# SpeechRecognition
Project 2 for Deep Learning course. Speech Recognition challange from Kaggle.
Link to the interactive google colab: https://colab.research.google.com/drive/1px3l0zPfwYvim6Um9bv_PjrGOibgbCZ7?usp=sharing

---

**Abstract**: Speech recognition has become a vital area of research in machine learning, en- abling technologies such as virtual assistants, automated transcription, and voice-controlled systems. A specific subtask within this domain—the classification of spoken words from raw audio—poses unique challenges, including temporal dynamics, speaker variability, and background noise. Traditional systems primarily relied on Hidden Markov Models (HMMs) combined with Gaussian Mixture Models (GMMs) to model the temporal and acoustic prop- erties of speech signals. While effective to a degree, these methods were limited in their ability to capture complex feature representations, particularly in real-world conditions.
Recent advances in neural network-based approaches have opened new possibilities for im- proving both accuracy and efficiency. These include Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and more recently, Transformer-based architectures, which have demonstrated state-of-the-art performance in many speech-related tasks.
In this study, we focus on the classification of spoken words using deep learning methods, with a particular emphasis on Transformer-based models. We systematically compare var- ious architectures, hyperparameter settings, and data augmentation techniques to identify optimal configurations. Our findings contribute to a deeper understanding of how different architectural choices impact performance, and offer practical guidance for designing effective word-level speech classification systems.

**Keywords**: speech recognition, data augmentation, deep learning, Transformers
